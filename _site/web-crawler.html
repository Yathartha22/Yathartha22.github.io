<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Web Crawlers and Web Crawling &middot; Yathartha Joshi
    

  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>



  <body>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100789460-1', 'auto');
  ga('send', 'pageview');

</script>

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">

  <div class="sidebar-logo" style="margin-top:40px; margin-left:70px;">
      <img style="border-radius:50%" src="http://www.gravatar.com/avatar/dcef76307de7fa9058c7f9d33a8277aa?s=120" />
  </div>
  
  <div id="contact-list" style="text-align:center">
      
        <a href="https://github.com/Yathartha22">
          <span class="fa-stack fa-lg">
            <i class="fa fa-square-o fa-stack-2x"></i>
            <i class="fa fa-github-alt fa-stack-1x"></i>
          </span>
        </a>
      
  </div>


  <div class="sidebar-item">
    <p>A personal website about technical things I find useful.
</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="/about">About</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/archive">Archive</a>
        
      
    
      
    
      
    
      
        
      
    
      
        
      
    
      
    
      
    

    <a class="sidebar-nav-item" href="">GitHub project</a>
    <span class="sidebar-nav-item">Currently v1.0.1</span>
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2018. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Yathartha Joshi</a>
            <small>Open Source Enthusiast</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">Web Crawlers and Web Crawling</h1>
  <span class="post-date">07 Jul 2017</span>
   <p><img src="/public/web-crawlers.jpg" style="width:30%;height:30%" /></p>

<p>Ever wondered how a search engine comes up with the exact results when you type something in its query box? After all, there are trillions of results matching your search query. A fascinating process is at work behind it. It is the <strong>Web Crawler</strong> that is responsible for accomplishing the task. So what is a <code class="highlighter-rouge">web crawler</code>, what it does and how it does, I will try to answer all these.</p>

<p><strong>What is a Web Crawler</strong></p>

<blockquote>
  <p><em>Web Crawler</em> or simply a <em>Crawler</em> is a program that acts as an automated script which browses through the internet in a systematic way.</p>
</blockquote>

<p>Web Crawlers are also known as <code class="highlighter-rouge">Spiders</code>, <code class="highlighter-rouge">Robot</code>, <code class="highlighter-rouge">SearchBot</code> or simply <code class="highlighter-rouge">Bot</code>. Web crawlers are one of the most common used systems now-a-days. The most popular example is that <em>Google</em> is using crawlers to collect information from all websites.</p>

<p>A <code class="highlighter-rouge">Search Engine Spider</code> is a program that most search engines use to find what‚Äôs new on the Internet. The crawler looks at the keywords in the pages, the kind of content each page has and the links, before returning the information to the search engine. This process is known as <code class="highlighter-rouge">Web crawling</code>.</p>

<p>Besides search engine, news websites need crawlers to aggregate data sources. It seems that whenever you want to aggregate a large amount of information, you may consider using crawlers.</p>

<p><strong>Why is Web Crawling Important</strong></p>

<p>Let me make you understand with an example to show why web crawling is important.</p>

<p>Data lies in the heart of any business, even more if its tech related. With all the open standards of today like RSS feeds or APIs sharing data across systems have become relatively easier.</p>

<p>For example, if you want to read today‚Äôs financial news directly from your email inbox, you could simply subscribe to the provider‚Äôs (like Google News or BBC) RSS feed. Similarly, your system or application could also use a provider‚Äôs API to get upto date information.
But what about data that is unstructured or does not have RSS feeds for you to consume? How will you go about fetching them?</p>

<p>Let‚Äôs consider another simple example. Suppose you have a shopping site and have 1000 products. You want to make sure your prices are competitive. In order to do that, you will need to monitor your competitors‚Äô sites and their prices for the same products. If there are a lot of products and lot of competitors it is going to be very difficult to do this without some automated process.</p>

<p>This is where <code class="highlighter-rouge">Web Crawling</code> comes into picture.</p>

<p><code class="highlighter-rouge">Web Crawling</code> technology was made popular by Google for its use in their search. They were the first to see the importance of immense amount of data on the web which was then not crawled and indexed. They capitalized on that ‚Äì sent out thousands of crawlers to the web and indexed everything they could possibly find!</p>

<p>To sum up let‚Äôs get few points summarized as to why web crawling is important:</p>

<ul>
  <li>
    <p>Gather data for business intelligence.</p>
  </li>
  <li>
    <p>Market research about the product or service you are offering.</p>
  </li>
  <li>
    <p>Monitor competitor‚Äôs product or solution 24/7.</p>
  </li>
  <li>
    <p>Gather user behavior data to make your product perform better.</p>
  </li>
</ul>

<p><strong>How does a Web Crawler work</strong></p>

<p>In short as explained by <a href="https://support.google.com/webmasters/answer/70897?hl=en">Google</a> on how Google Search works, for web crawling procedure there are mainly three steps:</p>

<ul>
  <li>First, the search bot starts by crawling the pages of your site(<strong>Crawling</strong>).</li>
  <li>Then it continues indexing the words and content of the site(<strong>Indexing</strong>), and</li>
  <li>finally it visit the links (web page addresses or URLs) that are found in your site.</li>
</ul>

<p>To control the way a spider looks to your website is by using a <strong>robots.txt</strong> file. The first thing a spider is supposed to do when it visits your website is look for a file called <em>robots.txt</em>. This file contains instructions for the spider on which parts of the website to index, and which parts to ignore.</p>

<p>Another piece of information I would share is the following answer in <strong>Quora</strong>, when asked</p>

<p><strong><em>What are some ideas of how a startup can use web crawler scripts to drive growth?</em></strong></p>

<p><img src="/public/quora-web-crawler-answer.png" style="height=30%" /></p>

<p>This was just an idea about <code class="highlighter-rouge">web crawlers</code> and <code class="highlighter-rouge">web crawling</code>. Hope, this might help you to get started with crawlers. Till then All the Best üëç and Happy Coding üòÉ</p>


<a class="github-button" href="https://github.com/Yathartha22" data-size="large" aria-label="Follow @Yathartha22 on GitHub">Follow 	             @Yathartha22</a>
<script async defer src="https://buttons.github.io/buttons.js"></script>
   

<div id="disqus_thread"></div>

<script type="text/javascript">
/* * * CONFIGURATION VARIABLES * * */
var disqus_shortname = 'yathartha22-github-io' ;

 /* * * DON'T EDIT BELOW THIS LINE * * */
 (function() {
   var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
   dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
   (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
 })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


 </div>

<div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/gsoc-week-6">
            GSoC 2018 - Week 6 - Continuing with transolve Part-III
            <small>23 Jun 2018</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/gsoc-week-5">
            GSoC 2018 - Week 5 - Implementing log solver
            <small>17 Jun 2018</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/gsoc-week-4">
            GSoC 2018 - Week 4 - Continuing with transolve Part-II
            <small>09 Jun 2018</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>

        

<div id="disqus_thread"></div>

<script type="text/javascript">
/* * * CONFIGURATION VARIABLES * * */
var disqus_shortname = 'yathartha22-github-io' ;

 /* * * DON'T EDIT BELOW THIS LINE * * */
 (function() {
   var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
   dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
   (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
 })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


      </div>
    </div>
    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
